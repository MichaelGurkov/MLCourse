---
title: "Homework3"
---

```{r include=FALSE}

knitr::opts_chunk$set(echo = FALSE, error = FALSE, warning = FALSE, message = FALSE)

```

```{r load_libraries}

library(tidyverse)
library(tidymodels)
library(magrittr)
library(tidymodels)
library(caret)
library(DALEX)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(ada)
library(doParallel)
library(pROC)

```

```{r set_parallel, eval=FALSE}

cl <- makePSOCKcluster(5)
registerDoParallel(cl)

```


```{r load_data}

heart = read_csv(here::here("data","heart.csv"))

```

```{r split_train_test}

set.seed(167)

heart_split = initial_split(heart)

train_heart = training(heart_split)

test_heart = testing(heart_split)

```



# Preface
A1: As I see it tuning parameters is a process of finding the value of a parameter that maximizes our target function. If take this definition then we do tune parameters in OLS or logistic regression in a way the difference being the all
the parameter "adjustment" is performed analytically and in one stage.

A2: Trees are considered path dependent because the success of each step (that actually means finding the variable that reduces the target variance) is
depended on the success of previous steps. In order 

```{r}

formula_part <- target ~ sex + cp + chol
formula_full <- target ~ .

```

```{r tree_model}

tree_model = rpart(formula = formula_part,data = train_heart,method = "class")

```


```{r plot_tree}

fancyRpartPlot(tree_model, caption = NULL)

```


```{r compare_model_restrictions}

restricted_tree_model = rpart(formula = formula_part,data = train_heart,
                       method = "class",minsplit = 2,minbucket = 1)

prune_tree_model = rpart(formula = formula_part,data = train_heart,
                       method = "class",cp = 0.03)

printcp(tree_model)

printcp(restricted_tree_model)

```

```{r predict}

predict(tree_model,train_heart,type = "class") %>% 
  as_tibble() %>% 
  bind_cols(pred = factor(train_heart$target, levels = c(0,1))) %>% 
  conf_mat(value, pred)

predict(tree_model,train_heart,type = "class") %>% 
  as_tibble() %>% 
  bind_cols(pred = factor(train_heart$target, levels = c(0,1))) %>% 
  accuracy(truth = value, estimate = pred)
  

predict(tree_model,test_heart,type = "class") %>% 
  as_tibble() %>% 
  bind_cols(pred = factor(test_heart$target, levels = c(0,1))) %>% 
  accuracy(truth = value, estimate = pred)

predict(tree_model,test_heart,type = "class") %>% 
  as_tibble() %>% 
  bind_cols(pred = factor(test_heart$target, levels = c(0,1))) %>% 
  conf_mat(value, pred)


```

```{r evaluate_prune_model}

predict(prune_tree_model,train_heart,type = "class") %>% 
  as_tibble() %>% 
  bind_cols(pred = factor(train_heart$target, levels = c(0,1))) %>% 
  conf_mat(value, pred)
  

predict(prune_tree_model,test_heart,type = "class") %>% 
  as_tibble() %>% 
  bind_cols(pred = factor(test_heart$target, levels = c(0,1))) %>% 
  accuracy(truth = value, estimate = pred)

```

